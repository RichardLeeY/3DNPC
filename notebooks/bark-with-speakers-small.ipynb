{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e1f274",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU sagemaker boto3 bark scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7facf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import io\n",
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "import time\n",
    "import shutil\n",
    "import json\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# S3 bucket for saving code and model artifacts.\n",
    "# Feel free to specify a different bucket here if you wish.\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = \"bark\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "6192cb22",
   "metadata": {},
   "source": [
    "# downloading model, upload to s3 (optional if you already downloaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc7bae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download s5cmd\n",
    "!curl -L https://github.com/peak/s5cmd/releases/download/v2.0.0/s5cmd_2.0.0_Linux-64bit.tar.gz | tar -xz\n",
    "!chmod 777 s5cmd\n",
    "\n",
    "#choose  suno/bark model\n",
    "repo_id=\"suno/bark-small\"  #change this to yours\n",
    "#local_dir='/tmp/'+repo_id.split(\"/\")[-1] #absolute or relative directory\n",
    "%mkdir suno\n",
    "local_dir=repo_id\n",
    "\n",
    "#download suno/bark model file from Hugging Face\n",
    "model_download_path = snapshot_download(repo_id=repo_id,local_dir=local_dir,ignore_patterns=[\"*.msgpack\",\"*.h5\"])\n",
    "print(model_download_path)\n",
    "!ls $local_dir\n",
    "\n",
    "#upload model files to s3 bucket\n",
    "!./s5cmd sync $local_dir/ s3://$bucket/$repo_id/\n",
    "!aws s3 ls s3://$bucket/$repo_id/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a5af8d",
   "metadata": {},
   "source": [
    "prepare code, and deploy to sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2cf2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare training files\n",
    "source_dir='code'\n",
    "\n",
    "if os.path.exists(source_dir):\n",
    "    shutil.rmtree(source_dir)\n",
    "!mkdir $source_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971bf142",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile code/requirements.txt\n",
    "transformers\n",
    "s3fs\n",
    "nvgpu\n",
    "pynvml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b6f005",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile code/inference.py\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import s3fs\n",
    "\n",
    "from transformers import AutoProcessor, BarkModel\n",
    "\n",
    "\n",
    "model = None\n",
    "processor = None\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print(f\"cwd:{cwd}\")\n",
    "dir_list = os.listdir(cwd)\n",
    "print(\"Files and directories in '\", cwd, \"' :\")\n",
    "# prints all files\n",
    "print(dir_list)\n",
    "\n",
    "model_local_path=f\"/tmp/bark/\"\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    global processor\n",
    "    \"\"\"\n",
    "    Deserialize and return fitted model.\n",
    "    \"\"\"\n",
    "    print(f\"model_dir: {model_dir}\")\n",
    "    \n",
    "    fs = s3fs.S3FileSystem()\n",
    "    model_s3 = os.environ.get(\"model_s3\", \"s3://sagemaker-us-east-1-845524701534/suno/bark-small/\")\n",
    "\n",
    "    print(f\"need copy {model_s3} to {model_local_path}\")\n",
    "    os.makedirs(model_local_path)\n",
    "    fs.get(model_s3,model_local_path, recursive=True)\n",
    "    dir_list = os.listdir(model_local_path)\n",
    "    print(\"Files and directories in '\", model_local_path, \"' :\")\n",
    "    print(dir_list)\n",
    "\n",
    "    print(\"download completed\")\n",
    "    \n",
    "    print(\"model_fn start\")\n",
    "    processor = AutoProcessor.from_pretrained(model_local_path,local_files_only=True)\n",
    "    print(\"model_fn start - loaded AutoProcessor\")\n",
    "    model = BarkModel.from_pretrained(model_local_path,local_files_only=True,torch_dtype=torch.float16).to(device)\n",
    "    print(\"model_fn start - loaded BarkModel\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    global processor\n",
    "    print(\"predict_fn start\")\n",
    "    if input_data is None:\n",
    "        input_data = {\"voice_preset\":\"v2/en_speaker_6\",\"text\":\"Hello, this is the default text\"}\n",
    "\n",
    "    if(model is None or processor is None):\n",
    "        print(\"model is None or processor is None. Auto loading\")\n",
    "        processor = AutoProcessor.from_pretrained(model_local_path)\n",
    "        model = BarkModel.from_pretrained(model_local_path).to(device)\n",
    "        \n",
    "    print(\"inputs start\")\n",
    "    inputs = processor(input_data[\"text\"], voice_preset=input_data[\"voice_preset\"]).to(device)\n",
    "    \n",
    "    print(\"model.generate start\")\n",
    "    audio_array = model.generate(**inputs)\n",
    "    print(\"output start\")\n",
    "    output = audio_array.cpu().numpy().squeeze()\n",
    "    return {\"output\":output}\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    print(f\"input_fn start\")\n",
    "    input_data = json.loads(request_body)\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fb52d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"local_dir=\",local_dir)\n",
    "#同步code目录下的文件到s3\n",
    "!./s5cmd sync $local_dir/ s3://$bucket/$repo_id/\n",
    "%cd\n",
    "%cd SageMaker\n",
    "!rm -rf dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c9de11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建空model.tar.gz文件上传到s3路径\n",
    "framework_version = '2.1.0'\n",
    "py_version = 'py310'\n",
    "\n",
    "!touch dummy\n",
    "!tar czvf model.tar.gz dummy\n",
    "model_data = 's3://{0}/{1}/model.tar.gz'.format(bucket, 'suno/bark-small')\n",
    "!aws s3 cp model.tar.gz $model_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a5e70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "model_s3 = 's3://{0}/{1}/'.format(bucket,'suno/bark-small')\n",
    "print(\"model_s3:\",model_s3)\n",
    "env = {\n",
    "    'SAGEMAKER_MODEL_SERVER_TIMEOUT':'6000', \n",
    "    'SAGEMAKER_MODEL_SERVER_WORKERS': '2', \n",
    "    'MMS_MAX_RESPONSE_SIZE':'65535000',\n",
    "    'TS_MAX_RESPONSE_SIZE':'65535000',\n",
    "    'model_s3':model_s3,\n",
    "}\n",
    "\n",
    "pytorchModel = PyTorchModel(\n",
    "    name = None,\n",
    "    model_data = model_data,\n",
    "    entry_point = 'inference.py',\n",
    "    source_dir = \"./code/\",\n",
    "    role = role,\n",
    "    framework_version = framework_version, \n",
    "    py_version = py_version,\n",
    "    env = env\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74270ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor = pytorchModel.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g5.2xlarge\",\n",
    "    serializer = JSONSerializer(),\n",
    "    deserializer = JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23d4735",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = predictor.endpoint_name\n",
    "print(f\"endpoint_name: {endpoint_name}\") #copy this endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2882ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bark import SAMPLE_RATE, generate_audio, preload_models\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b844b006",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#test speaker 1\n",
    "input_data = {\"voice_preset\":\"v2/en_speaker_9\",\"text\":\"Hello, this is the default text\"}\n",
    "predictions = predictor.predict(data = input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27fb991",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"type of output:\",type(predictions[\"output\"]))\n",
    "Audio(predictions[\"output\"], rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32bffba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create a custom configuration with the timeout\n",
    "from botocore.config import Config\n",
    "timeout = 300\n",
    "config = Config(\n",
    "    read_timeout=timeout,\n",
    "    connect_timeout=timeout,\n",
    "    region_name=\"us-east-1\"\n",
    ")\n",
    "runtime = boto3.Session().client('sagemaker-runtime',config=config)\n",
    "input_data = {\"voice_preset\":\"v2/zh_speaker_3\",\"text\":\"你还小看这件事！\"}\n",
    "payload = json.dumps(input_data).encode('utf-8')\n",
    "response = runtime.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                   ContentType='application/json',\n",
    "                                   Body=payload)\n",
    "print(response)\n",
    "audio_data = response[\"Body\"].read()\n",
    "print(\"type:\",type(audio_data))\n",
    "# string_obj = audio_data.decode('utf-8')\n",
    "json_obj = json.loads(audio_data)\n",
    "print(\"type2\",type(json_obj))\n",
    "wav = json_obj[\"output\"]\n",
    "print(\"type3\",type(wav))\n",
    "Audio(wav, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be36f4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "input_string = {[\"123\",\"1232\"],[\"111\",\"222\"]}\n",
    "json_obj = json.loads(input_string)\n",
    "first_object = json_obj[0]\n",
    "\n",
    "print(first_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8342d813",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#test speaker 2\n",
    "input_data = {\"voice_preset\":\"v2/en_speaker_9\",\"text\":\"Are you Crazy!!! What are you going to do!\"}\n",
    "predictions = predictor.predict(data = input_data)\n",
    "Audio(predictions[\"output\"], rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139c40e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#test speaker 2\n",
    "input_data = {\"voice_preset\":\"v2/en_speaker_9\",\"text\":\"Are you Crazy!!! What are you going to do!\"}\n",
    "predictions = predictor.predict(data = input_data)\n",
    "Audio(predictions[\"output\"], rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f9ca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#test speaker 2\n",
    "input_data = {\"voice_preset\":\"v2/en_speaker_9\",\"text\":\"Are you Crazy!!! What are you going to do!\"}\n",
    "predictions = predictor.predict(data = input_data)\n",
    "Audio(predictions[\"output\"], rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cef0a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
